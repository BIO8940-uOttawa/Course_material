---
title: "Revision about linear models"
subtitle: "in R"
author: "Julien Martin"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  xaringan::moon_reader:
    css: ["assets/css/rutgers-bki.css", "assets/css/rutgers-fonts_og.css"]
    lib_dir: "assets/libs"
    self_contained: true
    ratio: '16:9'
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.align = "center"
)

## load packages
library(car)
library(performance)
library(lmtest)
library(tidyverse)
```

```{r xaringan-panelset, echo=FALSE}
xaringanExtra::use_panelset()
xaringanExtra::use_tile_view()
```


## What is a linear regression

### Simple linear regression

$$Y_i = \beta_0 + \beta_1 x_i + \epsilon$$

or in distributional notation

$$Y \sim N(\beta_0 + \beta_1 x, \sigma^2)$$
 
--

### General linear model

$$Y_i = \beta_0 + \beta_1 x_{1i} + \beta_1 x_{2i} + ... + \epsilon$$

and 

$$Y \sim N(\beta_0 + \beta_1 x_{1i} + \beta_1 x_{2i} + ..., \sigma^2)$$

---

## Linear model assumptions

Some are made on the residuals and others on the independent variables. None are made on the (unconditionned) dependent variable. 

Residuals are assumed to:

- have a mean of zero
- be independent
- be normally distributed
- be homoscedastic

--

Independent variables are assumed to:

- have a linear relation with Y
- be measured without error
- to be independent from each other

---

## Maximum likelihood

Technique used for estimating the parameters of a given distribution, using some observed data

--

For Example: Population is known to follow a “normal distribution” but “mean” and “variance” are unknown, MLE can be used to estimate them using a limited sample of the population.

---

## Likelihood vs probability

We maximize the likelihood and make inferences on the probability

### Likelihood

$$L(parameters | data)$$
How likely it is to get those parameters given the data.

### Probability

$$P(data | null parameters)$$

Probability to get the data given the null parameters. Or how probable it is to get those data according to the null model.

---

## Maximum likelihood approach

$$L(parameters | data) = \prod_{i=1}^{n} f(data_i | parameters)$$

where f is the probability density function of your model.

--

Working with product is more painful than with sum, we can take the log:

$$ln(L(parameters | data)) = \sum_{i=1}^{n} ln(f(data_i | parameters))$$

--

Need to solve:

$$\frac{\delta ln(L(parameters | data)}{\delta parameters} = 0$$

For multiple regression, the parameters $\beta$s are given by $\beta = (X^T X)^{-1} X^T y$.

Equivalent to minimizing residuals (but you don't want to see the proof)

---

## Doing linear models in R


Simply use `lm()` function.
It works for everything anova, ancova, t-test.

--

We will use data of sturgeon measurements at different locations in Canada.

--

```{r}
dat <- read.csv("lm_example.csv")
str(dat)
```

---

## Fitting a model and checking assumptions

First we load the needed packages for:

* data manipulation: `tidyverse`
* fancy plots: `ggplot2`
* type III anova: `car`
* fancy and nicer visual assumptions checks: `performance`
* formal assumptions tests: `lmtest`

--

```{r, eval = FALSE, warning = FALSE, message = FALSE}
library(car)
library(performance)
library(lmtest)
library(tidyverse) #<<
```

---

## Data exploration
.panelset.sideways[

.panel[.panel-name[R Code]
```{r plot1, out.width = '500px', fig.show='hide'}
ggplot(data = dat, aes(x = age, y = fklngth)) +
  facet_grid(. ~ locate) +
  geom_point() +
  stat_smooth(method = lm, se = FALSE) +
  stat_smooth(se = FALSE, color = "red") +
  labs(
    y = "Fork length",
    x = "Age"
  )
```
]

.panel[.panel-name[Plot]
```{r plot1, echo=FALSE, out.width = '500px',fig.show='show'}
```
]
]
---

## Creating log10 transform

```{r}
dat <- dat %>%
  mutate(
    lage = log10(age),
    lfkl = log10(fklngth)
  )
```

---

## Data exploration: with log

.panelset.sideways[

```{r panelset=c(source = "Code", output = "Plot"), out.width = '500px'}
ggplot(data = dat, aes(x = lage, y = lfkl)) +
  facet_grid(. ~ locate) +
  geom_point() +
  stat_smooth(method = lm, se = FALSE) +
  stat_smooth(se = FALSE, color = "red") +
  labs(
    y = "log 10 Fork length",
    x = "Log 10 Age"
  )
```
]


---

## Fit the model

```{r}
m1 <- lm(lfkl ~ lage + locate + lage:locate, data = dat)
summary(m1)
```

---

### Anova for factors
```{r}
Anova(m1, type = 3)
```

---

## Assumptions (classic plot)
```{r, out.width = '450px'}
par(mfrow = c(2, 2))
plot(m1)
```

---

## Assumptions (Nicer plot)

```{r, out.width = '450px'}
check_model(m1)
```

---

## Formal tests

### Normality of residuals

```{r}
shapiro.test(residuals(m1))
```

---

## Formal tests

### Heteroscedasticity

```{r}
bptest(m1)
```
---

## Formal tests

### Linearity

```{r}
resettest(m1, power = 2:3, type = "fitted", data = dat)
```
---
class: center

# Happy coding

![](assets/unicorn.png)